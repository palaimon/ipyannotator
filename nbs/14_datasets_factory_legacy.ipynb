{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.factory_legacy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from ipyannotator.base import Settings\n",
    "from ipyannotator.datasets.download import (get_cifar10,\n",
    "                                            get_cub_200_2011,\n",
    "                                            get_oxford_102_flowers)\n",
    "from ipyannotator.datasets.generators_legacy import create_color_classification\n",
    "\n",
    "from ipyannotator.datasets.generators import create_object_detection, xyxy_to_xywh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class DS(Enum):\n",
    "    ARTIFICIAL_CLASSIFICATION = auto()\n",
    "    ARTIFICIAL_DETECTION = auto()\n",
    "    CIFAR10 = auto()\n",
    "    CUB200 = auto()\n",
    "    OXFORD102 = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_settings(dataset: DS):\n",
    "    \"\"\"\n",
    "    Handle the necessary to dowload and save the datasets\n",
    "    \"\"\"\n",
    "    if dataset == DS.ARTIFICIAL_CLASSIFICATION:\n",
    "        project_path = Path('data/artificial_classification/')\n",
    "        project_file = project_path / 'annotations.json'\n",
    "        image_dir = 'images'\n",
    "        create_color_classification(path=project_path, n_samples=50, size=(500, 500))\n",
    "        annotations = pd.read_json(project_file).T['labels'].to_dict()\n",
    "        anno = {str(project_path / image_dir / k): [f'{v}.jpg'] for k, v in annotations.items()}\n",
    "\n",
    "        with open(project_file, 'w') as f:\n",
    "            json.dump(anno, f)\n",
    "\n",
    "        return Settings(project_path=project_path,\n",
    "                        project_file=project_file,\n",
    "                        image_dir=image_dir,\n",
    "                        label_dir='class_images',\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=30, label_height=30,\n",
    "                        n_cols=3)\n",
    "\n",
    "    elif dataset == DS.ARTIFICIAL_DETECTION:\n",
    "        project_path = Path('data/artificial_detection/')\n",
    "        project_file = project_path / 'annotations.json'\n",
    "        image_dir = 'images'\n",
    "        label_dir = None\n",
    "        im_width = 200\n",
    "        im_height = im_width\n",
    "\n",
    "        create_object_detection(path=project_path, n_samples=50, n_objects=1, size=(500, 500))\n",
    "        annotations = pd.read_json(project_file).T\n",
    "\n",
    "        \"\"\"Convert artifical dataset annotations to old bbox ipyannotator format\n",
    "        {'imagename.jpg': {\n",
    "            'bbox': [{'x':0, 'y': 0, 'width': 100, 'heigth': 100}],\n",
    "            'labels': [[]]\n",
    "        }}\"\"\"\n",
    "        anno = annotations.T.to_dict('records')[0]\n",
    "        annotation_on_explore = {}\n",
    "        bbox_keys = ['x', 'y', 'width', 'height']\n",
    "\n",
    "        for k, v in anno.items():\n",
    "            key = os.path.join(project_path, image_dir, k)\n",
    "            value = dict(\n",
    "                zip(bbox_keys, xyxy_to_xywh(v))\n",
    "            )\n",
    "            annotation_on_explore[key] = {'bbox': [value], 'labels': [[]]}\n",
    "\n",
    "        with open(project_file, 'w') as f:\n",
    "            json.dump(annotation_on_explore, f)\n",
    "\n",
    "        return Settings(project_path=project_path,\n",
    "                        project_file=project_file,\n",
    "                        image_dir=image_dir,\n",
    "                        label_dir=label_dir,\n",
    "                        result_dir='create_results',\n",
    "                        im_width=im_width, im_height=im_height)\n",
    "\n",
    "    elif dataset == DS.CIFAR10:\n",
    "        cifar_train_p, cifar_test_p = get_cifar10(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/cifar10/'),\n",
    "                        project_file=cifar_test_p,\n",
    "                        image_dir='test',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=140, label_height=30,\n",
    "                        n_cols=2)\n",
    "\n",
    "    elif dataset == DS.OXFORD102:\n",
    "        flowers102_train_p, flowers102_test_p = get_oxford_102_flowers(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/oxford-102-flowers'),\n",
    "                        project_file=flowers102_test_p,\n",
    "                        image_dir='jpg',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=40, label_height=30,\n",
    "                        n_cols=7)\n",
    "\n",
    "    elif dataset == DS.CUB200:\n",
    "        cub200_train_p, cub200_test_p = get_cub_200_2011(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/CUB_200_2011'),\n",
    "                        project_file=cub200_test_p,\n",
    "                        image_dir='images',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=50, label_height=50,\n",
    "                        n_cols=7)\n",
    "    else:\n",
    "        raise UserWarning(f\"Dataset {dataset} is not supported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _combine_train_test(project_path: Path):\n",
    "    # combine train/test in one json file.\n",
    "    # Used to generate all possible class labels\n",
    "    all_annotations = project_path / \"annotations.json\"\n",
    "\n",
    "    with open(project_path / \"annotations_train.json\", \"rb\") as train:\n",
    "        tr = json.load(train)\n",
    "\n",
    "    with open(project_path / \"annotations_test.json\", \"rb\") as test:\n",
    "        te = json.load(test)\n",
    "\n",
    "    with open(all_annotations, \"w\") as outfile:\n",
    "        json.dump({**tr, **te}, outfile)\n",
    "    return all_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
