{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import json\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from ipyannotator.base import Settings\n",
    "from ipyannotator.datasets.download import (get_cifar10,\n",
    "                                            get_cub_200_2011,\n",
    "                                            get_oxford_102_flowers)\n",
    "from ipyannotator.datasets.generators import (\n",
    "    create_color_classification,\n",
    "    create_mot_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class DS(Enum):\n",
    "    ARTIFICIAL_VIDEO = auto()\n",
    "    ARTIFICIAL_BBOX = auto()\n",
    "    CIFAR10 = auto()\n",
    "    CUB200 = auto()\n",
    "    OXFORD102 = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_settings(dataset: DS):\n",
    "    \"\"\"\n",
    "    Handle the necessary to dowload and save the datasets.\n",
    "    Capable of dowloading CIFAR_10, OXFORD_102_FLOWERS, CUB_200 or a artificial dataset.\n",
    "    \"\"\"\n",
    "    if dataset == DS.ARTIFICIAL_BBOX:\n",
    "        project_path = Path('data/artificial/')\n",
    "        project_file = project_path / 'annotations.json'\n",
    "        image_dir = 'images'\n",
    "        _, annotations = create_color_classification(path=project_path, n_samples=50,\n",
    "                                                     size=(500, 500))\n",
    "\n",
    "        anno = {str(project_path / image_dir / k): [f'{v}.jpg'] for k, v in annotations.items()}\n",
    "\n",
    "        with open(project_file, 'w') as f:\n",
    "            json.dump(anno, f)\n",
    "\n",
    "        return Settings(project_path=project_path,\n",
    "                        project_file=project_file,\n",
    "                        image_dir=image_dir,\n",
    "                        label_dir='class_images',\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=30, label_height=30,\n",
    "                        n_cols=3)\n",
    "    elif dataset == DS.ARTIFICIAL_VIDEO:\n",
    "        project_path = Path('data/artificial/')\n",
    "        project_file = project_path / 'annotations.json'\n",
    "        image_dir = 'images'\n",
    "        create_mot_ds(project_path, image_dir, 20, True)\n",
    "        return Settings(\n",
    "            project_path=project_path,\n",
    "            project_file=project_file,\n",
    "            image_dir=image_dir,\n",
    "            im_width=200,\n",
    "            im_height=200,\n",
    "            result_dir='create_results',\n",
    "        )\n",
    "    elif dataset == DS.CIFAR10:\n",
    "        cifar_train_p, cifar_test_p = get_cifar10(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/cifar10/'),\n",
    "                        project_file=cifar_test_p,\n",
    "                        image_dir='test',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=140, label_height=30,\n",
    "                        n_cols=2)\n",
    "\n",
    "    elif dataset == DS.OXFORD102:\n",
    "        flowers102_train_p, flowers102_test_p = get_oxford_102_flowers(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/oxford-102-flowers'),\n",
    "                        project_file=flowers102_test_p,\n",
    "                        image_dir='jpg',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=40, label_height=30,\n",
    "                        n_cols=7)\n",
    "\n",
    "    elif dataset == DS.CUB200:\n",
    "        cub200_train_p, cub200_test_p = get_cub_200_2011(Path('data'))\n",
    "\n",
    "        return Settings(project_path=Path('data/CUB_200_2011'),\n",
    "                        project_file=cub200_test_p,\n",
    "                        image_dir='images',\n",
    "                        label_dir=None,\n",
    "                        # used on create step - should be empty!\n",
    "                        result_dir='create_results',\n",
    "                        im_width=50, im_height=50,\n",
    "                        label_width=50, label_height=50,\n",
    "                        n_cols=7)\n",
    "    else:\n",
    "        raise UserWarning(f\"Dataset {dataset} is not supported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _combine_train_test(project_path: Path):\n",
    "    # combine train/test in one json file.\n",
    "    # Used to generate all possible class labels\n",
    "    all_annotations = project_path / \"annotations.json\"\n",
    "\n",
    "    with open(project_path / \"annotations_train.json\", \"rb\") as train:\n",
    "        tr = json.load(train)\n",
    "\n",
    "    with open(project_path / \"annotations_test.json\", \"rb\") as test:\n",
    "        te = json.load(test)\n",
    "\n",
    "    with open(all_annotations, \"w\") as outfile:\n",
    "        json.dump({**tr, **te}, outfile)\n",
    "    return all_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
