{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ipyannotator.im2im_annotator import Im2ImAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose between 3 datasets ['cifar10', 'oxford_flowers', 'CUB_200'] that you can download.\n",
    "# We use a artifical generated classification dataset by default that doesn't require downloading.\n",
    "dataset = 'artifical'\n",
    "# dataset = 'cifar10'\n",
    "# dataset = 'oxford_flowers'\n",
    "# dataset = 'CUB_200'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.datasets.generators import create_color_classification\n",
    "\n",
    "if dataset == 'artifical':\n",
    "    import tempfile\n",
    "    tmp_dir = tempfile.TemporaryDirectory()\n",
    "    path = Path(tmp_dir.name)\n",
    "#     Convert artifical dataset annotations to ipyannotator format inplace\n",
    "    from PIL import Image\n",
    "    create_color_classification(path=path, n_samples=50, size=(500, 500))\n",
    "    annotations = pd.read_json(path/'annotations.json').T\n",
    "    \n",
    "    anno = annotations.T.to_dict('records')[0]\n",
    "    anno = {str(path / 'images' / k): [f'{v}.jpg'] for k,v in anno.items()}\n",
    "    with open(path/'annotations.json', 'w') as f:  \n",
    "        json.dump(anno, f)\n",
    "        \n",
    "    project_path = path\n",
    "    project_file = path/'annotations.json'\n",
    "    image_dir = 'images'\n",
    "    label_dir = 'class_images'\n",
    "    im_width=50 \n",
    "    im_height=50\n",
    "    label_width=30\n",
    "    label_height=30\n",
    "    n_cols = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.datasets.download import get_cifar10, get_cub_200_2011, get_oxford_102_flowers\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    cifar_train_p, cifar_test_p = get_cifar10('data')\n",
    "    project_path = 'data/cifar10/'\n",
    "    project_file = cifar_test_p\n",
    "    image_dir = 'test'\n",
    "    label_dir = None\n",
    "    \n",
    "    im_width=50 \n",
    "    im_height=50\n",
    "    label_width=140\n",
    "    label_height=30\n",
    "    n_cols = 2\n",
    "\n",
    "if dataset == 'oxford_flowers':\n",
    "    flowers102_train_p, flowers102_test_p = get_oxford_102_flowers('data')\n",
    "    project_path = 'data/oxford-102-flowers'\n",
    "    project_file = flowers102_test_p\n",
    "    image_dir = 'jpg'\n",
    "    label_dir = None\n",
    "    \n",
    "    im_width=50 \n",
    "    im_height=50\n",
    "    label_width=40\n",
    "    label_height=30\n",
    "    n_cols = 7\n",
    "    \n",
    "if dataset == 'CUB_200':\n",
    "    cub200_train_p, cub200_test_p = get_cub_200_2011('data')\n",
    "    project_path = 'data/CUB_200_2011'\n",
    "    project_file = cub200_test_p\n",
    "    image_dir='images'\n",
    "    label_dir = None\n",
    "    \n",
    "    im_width=50 \n",
    "    im_height=50\n",
    "    label_width=450\n",
    "    label_height=15\n",
    "    n_cols = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo convert datasets / create helper function\n",
    "\n",
    "for all three dataset, each has a different file / folder structure\n",
    "\n",
    "- should be possible to either look at train or test images\n",
    "- should be possible to look at unlabeled or labeled data\n",
    "\n",
    "comment: maybe we can borrow code from fastai `DataBunch` supports all this file/folder structures,\n",
    "however we shouldn't have fastai as dependency because this would also require pytorch which is fairly big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize existing annotated dataset.\n",
    "\n",
    "As we don't have images for each class we do not provide `label_dir=None` for ippyannotator, thus class labels will be generrated automatically based on `annotation.json` file.\n",
    "\n",
    "We use `results_dir` param to indicate directory where `annotation.json` file with existing annotations is located.\n",
    "\n",
    "You can explore dataset with `next/previous` buttons to check visualized labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {project_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2im = Im2ImAnnotator(project_path=project_path, \n",
    "                        file_name=project_file, \n",
    "                        image_dir=image_dir,\n",
    "                        step_down=True, \n",
    "                        label_dir=label_dir, \n",
    "                        im_width=im_width, im_height=im_height, \n",
    "                        label_width=label_width, label_height=label_height,\n",
    "                        n_cols=n_cols\n",
    "                       )\n",
    "im2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore only subset of ds\n",
    "\n",
    "import json\n",
    "from random import sample\n",
    "\n",
    "with project_file.open() as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "all_labels = data.values()\n",
    "unique_labels = set(label for item_labels in all_labels for label in item_labels)\n",
    "\n",
    "\n",
    "#  get <some> random labels and generate annotation file with them:\n",
    "some = 3\n",
    "assert (some <= len(unique_labels))\n",
    "subset_labels = sample([[a] for a in unique_labels], k=some)\n",
    "subset_annotations = {k:v for k, v in data.items() if v in subset_labels}\n",
    "\n",
    "subset_file = Path(project_path) / 'subset_anno.json'\n",
    "with subset_file.open('w', encoding='utf-8') as fi:\n",
    "    json.dump(subset_annotations, fi, ensure_ascii=False, indent=4)\n",
    "    \n",
    "\n",
    "# use it in annotator    \n",
    "im2im = Im2ImAnnotator(project_path=project_path, \n",
    "                       file_name=subset_file, \n",
    "                       image_dir=image_dir,\n",
    "                       step_down=True, \n",
    "                       label_dir=label_dir,\n",
    "                       im_width=im_width, im_height=im_height, \n",
    "                       label_width=label_width, label_height=label_height, \n",
    "                       n_cols=n_cols,\n",
    "                       label_autosize=False\n",
    "                      )\n",
    "im2im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unannotated dataset and create classification labels.\n",
    "\n",
    "- real\n",
    "- generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set `label_dir='class_images'`, because we have existing folder, where one image per class with proper name saved beforehand corespondinlgy\n",
    "\n",
    "Also, setting `results_dir=\"out\"` we define that final `annotation.json` file will be generated from scratch and saved to `{project_path}/out` direcory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to annotate some pieces incorrectly, thus you prepare good set for `improve` step below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  while we don't have class_labels for real datasets, let's combine train and test annotations to generate them\n",
    "\n",
    "all_annotations = Path(project_path) / \"annotations.json\"\n",
    "    \n",
    "if dataset != 'artifical':  # combine train/test for real ds\n",
    "    \n",
    "    import json\n",
    "    import glob\n",
    "\n",
    "    with open(Path(project_path) / \"annotations_train.json\", \"rb\") as train:\n",
    "        tr = json.load(train)\n",
    "\n",
    "\n",
    "    with open(Path(project_path) / \"annotations_test.json\", \"rb\") as test:\n",
    "        te = json.load(test)\n",
    "\n",
    "    result = {**tr, **te}\n",
    "\n",
    "    with open(all_annotations, \"w\") as outfile:\n",
    "         json.dump(result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_class_labels = Im2ImAnnotator(project_path=project_path, \n",
    "                       image_dir=image_dir, \n",
    "                       file_name=all_annotations,\n",
    "                       label_dir=label_dir, \n",
    "                       results_dir=None,\n",
    "                       im_width=im_width, im_height=im_height, \n",
    "                       label_width=label_width, label_height=label_height, \n",
    "                       n_cols=n_cols, \n",
    "                       question=\"Classification\")\n",
    "label_dir = gen_class_labels._model.label_dir.stem\n",
    "label_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now we can generate new annotaation file from scratch, \n",
    "#  by using empty folder for <results_dir> and <label_dir> from previous step\n",
    "\n",
    "output_dir = 'results'\n",
    "print(Path(project_path) / output_dir)\n",
    "!rm -rf {Path(project_path) / output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2im = Im2ImAnnotator(project_path=project_path, \n",
    "                       image_dir=image_dir,\n",
    "                       file_name=None,\n",
    "                       label_dir=label_dir, \n",
    "                       results_dir=output_dir,\n",
    "                       im_width=im_width, im_height=im_height, \n",
    "                       label_width=label_width, label_height=label_height, \n",
    "                       n_cols=n_cols, \n",
    "                       question=\"Classification\")\n",
    "\n",
    "im2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labelss = im2im._model.labels_files\n",
    "all_labelss[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with all_annotations.open() as f:\n",
    "    anno_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filt = np.random.uniform(low=0, high=1, size=len(anno_))\n",
    "\n",
    "label_noise = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy annotator\n",
    "from random import choice\n",
    "\n",
    "def get_random_class():\n",
    "    return choice (all_labelss)\n",
    "\n",
    "get_random_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign random label for subset of all annotations to imitate human work with <label_noise> amount of errors\n",
    "\n",
    "filtererd = {x: [get_random_class()] if f_ < label_noise else y for (x, y), f_ in zip(anno_.items(), filt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update ipyannotator's annotations bassed on previous step and save\n",
    "\n",
    "im2im._model.annotations.update((k, filtererd.get(k, [])) for k in im2im._model.annotations.keys())\n",
    "im2im._save_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im2im._model.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check annotation file on disk\n",
    "# !cat {im2im._model.annotation_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same in memory\n",
    "from IPython import display\n",
    "# im2im.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotated dataset and mark wrongly annotated samples.\n",
    "\n",
    "- real\n",
    "- generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create corresponding map for each class from annotations obtained on `create` step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open labels generated on [create] step\n",
    "\n",
    "with open(Path(project_path) / output_dir / 'annotations.json') as infile:\n",
    "    loaded_image_annotations = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_image_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def group_files_by_class(annotations):\n",
    "    grouped = defaultdict(list)\n",
    "    for file, labels in annotations.items():\n",
    "        for class_ in labels:\n",
    "            grouped[class_].append(file)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_files = group_files_by_class(loaded_image_annotations) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets group some annotators together, so we can go through all annotated images but for each classs separately.\n",
    "\n",
    "Each grid shows images belonging to the __same__ class. \n",
    "\n",
    "You should __mark all errors__ (images, which belongs to __different__ class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.capture_annotator import CaptureAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! Dont forget to click __SAVE__ button when finished with each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [CaptureAnnotator(project_path, image_dir, 50, 50, 2, 5,\n",
    "                          question=f'Check incorrect annotation for [{class_name[:-4]}] class', \n",
    "                          filter_files=class_anno,\n",
    "                          results_dir=f'{output_dir}/missed/{class_name[:-4]}') for class_name, class_anno in tqdm(classes_to_files.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's select first two classes to mark the errors \n",
    "widgets.VBox(children = items[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mark spoiled on create step, imitating human correction\n",
    "\n",
    "for i in tqdm(items):\n",
    "    for k, v in i._model.annotations.items():\n",
    "        i._model.annotations[k] = {'answer': anno_[k] != filtererd[k]}   \n",
    "        i._model._update_state()\n",
    "    i._save_btn.click()\n",
    "#     print(i._model.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get list of all marked images, which should be reclassified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclasify_this = [[c for c, v in i.to_dict().items() if v['answer']] for i in items]\n",
    "\n",
    "#  show 10 files with incorrect label for the first class\n",
    "reclasify_this[1][:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, auttomatically generarted json file can be used for each class.\n",
    "\n",
    "Let's load one random json and select filenames marked as incorrect on previous step for this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "random_class = sample(glob(str(Path(project_path) / output_dir/'missed')+'/*'), 1)[0]\n",
    "print(random_class)\n",
    "\n",
    "random_class_annotation = pd.read_json(Path(random_class) / 'annotations.json').T\n",
    "\n",
    "random_misssed = list(random_class_annotation[random_class_annotation['answer']==True].index.values)\n",
    "\n",
    "#  show 10 files with incorrect label for the random class \n",
    "random_misssed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
