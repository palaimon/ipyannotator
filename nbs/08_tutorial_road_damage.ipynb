{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Annotation Process with ipyannotator\n",
    "\n",
    "This tutorial demonstrates how you can build an annotated dataset for road damage classification without ever leaving the\n",
    "jupyter notebook / lab. We do this is three steps:\n",
    "\n",
    "1. Use bounding box annotation to crop the orignal imges.\n",
    "2. Group the damage type in groups using classification labels.\n",
    "3. Refine the inital class labels in a supervision step.\n",
    "\n",
    "This steps can be applied iteratively for practical applications and significantly speed up by integrating the predictions of imperfect machine learning models.\n",
    "For example we might train an image classification model on the first annotations and refine it's prediction on new data to increase the training data and repead the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Road Damage Images from BigData Cup 2020\n",
    "\n",
    "First we need to retrieve some images from which we can build or data set. Fortunately the [Global Road Damage Detection Challenge 2020](https://rdd2020.sekilab.global/data/) provides\n",
    "a freely usable images that we can download (Please cite [the paper](https://github.com/sekilab/RoadDamageDetector#citation) if you use this for your own work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux\n",
    "The following commandas will download and prepare the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/test1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xf test1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -h test1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir road_japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv test1/Japan/images road_japan/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r test1.tar.gz test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other OS\n",
    "\n",
    "Please complete the following manual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download the test1 dataset from https://github.com/sekilab/RoadDamageDetector#dataset-for-global-road-damage-detection-challenge-2020\n",
    "- unpack the `*.tar.gz` file\n",
    "- create a new folder `road_japan` next to this notebook\n",
    "- move the folder `test1/Japan/images` into `road_japan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Use bounding box annotation to crop the orignal imges.\n",
    "\n",
    "We can now use the BBoxAnnotator to quickly inspect the available images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.bbox_annotator import BBoxAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BBoxAnnotator(project_path='road_japan', image_dir='images', canvas_size=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a inital set of road damage images by using the mouse to draw a reactangle containing\n",
    "the damage on individual images. Below you seed the annotation for a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, bbox = list(bb.to_dict().items())[0]; print(img_path); bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the bounding box annotations to crop damages from the images and save them in a seperate folder.\n",
    "The following small function helps us to accomblish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def crop_bboxs(bbox_annotations, source_dir, target_dir):\n",
    "    Path(target_dir).mkdir(parents=True, exist_ok=True)\n",
    "    for img_file, b in bbox_annotations.items():\n",
    "        im = Image.open(Path(source_dir)/img_file)\n",
    "        # box=(left, upper, right, lower)\n",
    "        box_crop = (b['x'], b['y'], b['x'] + b['width'], b['y'] + b['height'])\n",
    "        Image.open(Path(source_dir)/img_file).crop(box_crop).save(Path(target_dir)/img_file, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_bboxs(bbox_annotations=bb.to_dict(), source_dir='road_japan/images', target_dir='road_japan/images_croped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the croping result from the bbox annotation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(Path('road_japan/images_croped')/img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to decide on the type of damages we want to classify. If we don't know this upfront we can initially create some\n",
    "dummy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy label_images\n",
    "crop_bboxs(bbox_annotations={k: v for k, v in list(bb.to_dict().items())[:4]}, source_dir='road_japan/images', target_dir='road_japan/class_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Group the damage type in groups using classification labels.\n",
    "\n",
    "1. We can now use the `Im2ImAnnotator` to quickly explore the croped images in order to find some typical damage types we are interested in. \n",
    "  * The competition list the following types {D00: Longitudinal Crack, D10: Transverse Crack, D20: Aligator Crack, D40: Pothole}.\n",
    "  * Hint: Check out https://en.wikipedia.org/wiki/Pavement_cracking to find some typical crack types.\n",
    "2. Select a reprecentative example for each damage type your are interessting and move the file to `road_japan/class_images`.\n",
    "  * remove the existing dummy images first\n",
    "  * give the image a nice name illustrative name such as aligator_crack.jpg. The file name is used to create the class labels.\n",
    "3. Label the images by selecting one or mare labels on the right side below \"Damage Types\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.im2im_annotator import Im2ImAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im2im_full = Im2ImAnnotator('../data/projects/im2im1', 'pics', 150,100, 50, 50, 2, 5, question=\"HelloWorld\")\n",
    "\n",
    "im2im = Im2ImAnnotator('road_japan', 'images_croped', 600, 500, 100, 100, 2, 3, question=\"Damage Types\")\n",
    "im2im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the class labels that we have just created and save them to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.JSON(im2im.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('road_japan/classification_labels.json', 'w') as outfile:\n",
    "    json.dump(im2im.to_dict(), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Refine the inital class labels in a supervision step.\n",
    "\n",
    "When the data have been labeled initially, supervision is a great way to further improve the data quality by reviewing annotations generated by hand or a\n",
    "machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text example data\n",
    "# image_annotations = {'Japan_000342.jpg': ['Japan_010778.jpg'],\n",
    "#  'Japan_000541.jpg': ['Japan_011190.jpg'],\n",
    "#  'Japan_001155.jpg': ['Japan_003206.jpg', 'Japan_010778.jpg'],\n",
    "#  'Japan_002337.jpg': ['Japan_001155.jpg'],\n",
    "#  'Japan_003206.jpg': ['Japan_011190.jpg'],\n",
    "#  'Japan_005979.jpg': ['Japan_010778.jpg'],\n",
    "#  'Japan_006775.jpg': ['Japan_003206.jpg'],\n",
    "#  'Japan_007389.jpg': ['Japan_003206.jpg'],\n",
    "#  'Japan_010778.jpg': ['Japan_003206.jpg', 'Japan_010778.jpg'],\n",
    "#  'Japan_011190.jpg': ['Japan_001155.jpg', 'Japan_010778.jpg'],\n",
    "#  'Japan_012213.jpg': ['Japan_011190.jpg']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the priviously generated class label to group the images by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('road_japan/classification_labels.json') as infile:\n",
    "    image_annotations= json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def group_files_by_class(annotations):\n",
    "    grouped = defaultdict(list)\n",
    "    for file, labels in annotations.items():\n",
    "        for class_ in labels:\n",
    "            grouped[class_].append(file)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_files = group_files_by_class(image_annotations); classes_to_files.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick any class to start the supervision, we just take the first one here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_class = list(classes_to_files.keys())[0]; selected_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes_to_files[selected_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotator.capture_annotator import CaptureAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_question = 'Select images that don\\'t belong to class <span style=\"color: red;\">{}</span>'.format(selected_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotator now shows us a grid of images annotated as belonging to the same class. You can now quickly click through\n",
    "this batches and select the images that belong in a different class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = CaptureAnnotator('road_japan', 'images_croped', 150, 150, 2, 2,\n",
    "                      question=html_question,\n",
    "                      filter_files=classes_to_files[selected_class])\n",
    "ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this process for each class and then reclassify the wrong labels in a later step. The Capture annotator is most useful when you already\n",
    "have imperfect image classifications for example form an pretrained model or you have many less experienced annotators and a limited amount of experts to check there work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short tutorial has demonstrated how annotation UI's already included in ipyannotator can be used to quickly annotate images.\n",
    "Clearly this a very simple examples and the real power of using the ipyannotator concept lays in building project specific UI's.\n",
    "Check out the other notebooks to get inspired how this can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
