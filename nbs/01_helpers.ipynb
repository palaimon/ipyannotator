{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "\n",
    "try:\n",
    "    from collections.abc import Iterable\n",
    "except ImportError:\n",
    "    from collections import Iterable\n",
    "\n",
    "\n",
    "def flatten(lis):\n",
    "    for item in lis:\n",
    "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "            for x in flatten(item):\n",
    "                yield x\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "assert (list(flatten([1, 2, [3, 4, 5, [6, 7]], 8, [9, 10]])) == list(range(1, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "list(flatten([1, 2, [3, 4], 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module to add utils for other modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import textwrap\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def text_on_img(text=\"Hello\", lbl_w=None, lbl_h=None, font_size=14, filepath=None):\n",
    "    \"\"\"\n",
    "        Render text in a image\n",
    "    \"\"\"\n",
    "\n",
    "    font = ImageFont.truetype(\"lte50712.ttf\", font_size)\n",
    "\n",
    "    if lbl_w is None:\n",
    "        lbl_w = 150\n",
    "    if lbl_h is None:\n",
    "        lbl_h = 150\n",
    "\n",
    "    assert(text)\n",
    "\n",
    "    text = text.upper()\n",
    "\n",
    "    m_width, m_heigth = font.getsize(\"M\")\n",
    "    char_num_per_line = lbl_w // m_width\n",
    "\n",
    "    image = Image.new(mode=\"RGB\", size=(lbl_w, lbl_h), color=\"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    words = text.split()\n",
    "    if len(words) <= 2 and all(font.getsize(w)[0] < lbl_w for w in words):\n",
    "        t_wrapper = words\n",
    "    else:\n",
    "        t_wrapper = textwrap.wrap(text, char_num_per_line)\n",
    "\n",
    "    offset = (lbl_h - (m_heigth * len(t_wrapper))) // 2\n",
    "\n",
    "    for line in t_wrapper:\n",
    "        line_w, line_h = font.getsize(line)\n",
    "        draw.text(((lbl_w - line_w) // 2, offset), line, font=font, fill=(0, 0, 0))\n",
    "        offset += line_h\n",
    "\n",
    "    if filepath:\n",
    "        image.save(filepath)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "display(text_on_img(text=\"new labe\"))\n",
    "display(text_on_img(text=\"longer label here\"))\n",
    "display(text_on_img(text=\"thelongestofthelonglabelishere\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def reconstruct_class_images(label_dir, annotation_file, lbl_w=None, lbl_h=None):\n",
    "    with open(annotation_file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        unique_classes = set(flatten(data.values()))  # ipyannotator format\n",
    "\n",
    "    for cl_name in unique_classes:\n",
    "        if cl_name is None:\n",
    "            cl_name = \"None\"\n",
    "\n",
    "        cl_im_name = f'{cl_name}.jpg' if not re.findall(r\"([-\\w]+\\.(?:jpg|png|jpeg))\",\n",
    "                                                        cl_name, re.IGNORECASE) else cl_name\n",
    "\n",
    "        text_on_img(text=os.path.splitext(cl_name)[0], filepath=label_dir / cl_im_name,\n",
    "                    lbl_w=lbl_w, lbl_h=lbl_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "fol = Path(tmp_dir.name) / 'autogenerated'\n",
    "fol.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "annotations = {\n",
    "    str(Path(tmp_dir.name) / 'img_0.jpg'): ['yellow.jpg'],\n",
    "    str(Path(tmp_dir.name) / 'img_1.jpg'): ['red'],\n",
    "    str(Path(tmp_dir.name) / 'img_2.jpg'): ['red']\n",
    "}\n",
    "\n",
    "annot_file = Path(tmp_dir.name) / 'annotations.json'\n",
    "with open(annot_file, 'w') as f:\n",
    "    json.dump(annotations, f, indent=2)\n",
    "\n",
    "reconstruct_class_images(fol, annot_file)\n",
    "\n",
    "#check if generated\n",
    "!ls {fol}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def augment(sig):\n",
    "    s = (sig[2] + sig[3]) // 2\n",
    "    return (sig + (np.random.rand(1, 4) * s - s / 2)).astype(int).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment(np.array([10, 10, 10, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from random import choice\n",
    "from ipyannotator.datasets.factory import DS as NDS\n",
    "from ipyannotator.datasets.factory_legacy import DS, _combine_train_test\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class Tutorial:\n",
    "    \"\"\"\n",
    "    Combines some algorithms to imitate human work with annotators\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: Union[DS, NDS], project_path):\n",
    "        self.dataset = dataset\n",
    "        self.project_path = project_path\n",
    "        if self.dataset not in [DS.ARTIFICIAL_CLASSIFICATION, DS.ARTIFICIAL_DETECTION,\n",
    "                                NDS.ARTIFICIAL_VIDEO]:\n",
    "            _combine_train_test(project_path)\n",
    "        self.all_annotations = Path(project_path) / \"annotations.json\"\n",
    "\n",
    "    # Random annotator used in image_classification tutorial [create]\n",
    "    def annotate_randomly(self, annotator):\n",
    "        with self.all_annotations.open() as f:\n",
    "            anno_ = json.load(f)\n",
    "\n",
    "        filt = np.random.uniform(low=0, high=1, size=len(anno_))\n",
    "\n",
    "        label_noise = 0.1\n",
    "\n",
    "        def get_random_class():\n",
    "            return choice(annotator.storage.get_labels())\n",
    "\n",
    "        # assign random label for subset of all annotations to imitate human work with\n",
    "        # <label_noise> amount of errors\n",
    "        self.filterered = {\n",
    "            x: [get_random_class()] if f_ < label_noise else y for (x, y),\n",
    "            f_ in zip(anno_.items(), filt)}\n",
    "\n",
    "        # update ipyannotator's annotations bassed on previous step and save\n",
    "        annotator.storage.update((k, self.filterered.get(k, [])) for k in annotator.storage.keys())\n",
    "        annotator.view._save_btn.click()\n",
    "\n",
    "    # Annotations fixer used in image_classification tutorial [improve]\n",
    "    def fix_incorrect_annotations(self, annotator):\n",
    "        with self.all_annotations.open() as f:\n",
    "            anno_ = json.load(f)\n",
    "\n",
    "        #  mark spoiled on create step, imitating human correction\n",
    "        for i in tqdm(annotator):\n",
    "            for j in range(i.app_state.max_im_number):\n",
    "                i.controller.idx_changed(j)\n",
    "                for k, v in i.capture_state.annotations.items():\n",
    "                    i.capture_state.annotations[k] = {'answer': anno_[k] != self.filterered[k]}\n",
    "                    i.view._save_btn.click()\n",
    "\n",
    "    # Random annotator used in bbox tutorial [create]\n",
    "    def add_random_bboxes(self, annotator):\n",
    "        with self.all_annotations.open() as f:\n",
    "            anno_ = json.load(f)\n",
    "\n",
    "        filt = np.random.uniform(low=0, high=1, size=len(anno_))\n",
    "\n",
    "        bbox_noise = 0.2\n",
    "\n",
    "        # lets randomly annotate each image from code and save annotations\n",
    "        for k, f_ in tqdm(zip(annotator.storage.keys(), filt)):\n",
    "            # do not overwrite existing annotations\n",
    "            if annotator.storage[k]:\n",
    "                continue\n",
    "\n",
    "            if f_ < bbox_noise:\n",
    "                values = []\n",
    "                assert isinstance(anno_[k]['bbox'], list)\n",
    "                for bbox in anno_[k]['bbox']:\n",
    "                    assert isinstance(bbox, dict)\n",
    "                    values.append(\n",
    "                        dict(\n",
    "                            zip(\n",
    "                                ['x', 'y', 'width', 'height'],\n",
    "                                augment(np.fromiter(bbox.values(), dtype=np.uint64))\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                annotator.storage[k] = {'bbox': values, 'labels': [[]]}\n",
    "            else:\n",
    "                annotator.storage[k] = anno_[k]\n",
    "\n",
    "        annotator.controller._update_coords(annotator.app_state.index)  # update screen\n",
    "\n",
    "        annotator.view._save_btn.click()  # save to file\n",
    "\n",
    "    # Annotations fixer used in bbox tutorial [improve]\n",
    "    def fix_incorrect_bboxes(self, improver, creator):\n",
    "        with self.all_annotations.open() as f:\n",
    "            anno_ = json.load(f)\n",
    "\n",
    "        im_dir_path = creator.storage.im_dir\n",
    "        improver.app_state.index = 0\n",
    "\n",
    "        for i in tqdm(range(improver.app_state.max_im_number)):\n",
    "            for k, v in improver.capture_state.annotations.items():\n",
    "                capture_im_path = Path(k)\n",
    "\n",
    "                index = capture_im_path.parts.index('captured') + 1\n",
    "                new_im_path = im_dir_path.joinpath(*capture_im_path.parts[index:])\n",
    "                v_expl = anno_.get(str(new_im_path), {})\n",
    "                v_cret = creator.storage.get(str(new_im_path), {})\n",
    "                improver.capture_state.annotations[k] = {'answer': v_expl != v_cret}\n",
    "            improver.view._navi._next_btn.click()\n",
    "\n",
    "    def annotate_video_bboxes(self, annotator) -> dict:\n",
    "        mot_gt = pd.read_csv(self.project_path / 'mot.csv')\n",
    "        mot_gt.columns = [\n",
    "            'frame',\n",
    "            'id',\n",
    "            'conf',\n",
    "            'label',\n",
    "            'vis',\n",
    "            'x',\n",
    "            'y',\n",
    "            'width',\n",
    "            'height',\n",
    "        ]\n",
    "        mot_gt.sort_values(by=['frame'])\n",
    "        mot_gt['frame'] = mot_gt['frame'].astype(str).str.zfill(4)\n",
    "        full_path = f'{self.project_path}/images'\n",
    "        mot_gt['frame'] = mot_gt['frame'].apply(lambda x: full_path + '/' + x + '.jpg')\n",
    "        mot_gt.index = mot_gt['frame']\n",
    "        mot_gt = mot_gt.drop(columns=['frame', 'conf', 'label', 'vis'])\n",
    "#         mot_gt = mot_gt[mot_gt.columns.drop(['frame', 'conf', 'label', 'vis'])]\n",
    "        mot_gt = mot_gt.groupby('frame').apply(lambda x: x.to_json(orient='records'))\n",
    "        result = mot_gt.to_json(orient='index')\n",
    "        parsed = json.loads(result)\n",
    "\n",
    "        # Hacky way to occlude the video tutorial avoiding\n",
    "        # to render indexes on specific frames\n",
    "        i = 0\n",
    "        annotations = {}\n",
    "        for k, v in parsed.items():\n",
    "            bboxes = json.loads(v)\n",
    "            for bbox in bboxes:\n",
    "                tmp_bbox = bbox.copy()\n",
    "                del bbox['id']\n",
    "                bbox['id'] = self._mutate_id(tmp_bbox, i)\n",
    "\n",
    "            if i < 4 or i > 8:\n",
    "                annotations[k] = {\n",
    "                    'bbox': bboxes,\n",
    "                    'labels': [self._bbox_to_label(bbox) for bbox in bboxes]\n",
    "                }\n",
    "            else:\n",
    "                # add circle annotation to specific frames\n",
    "                bboxes = [bbox for bbox in bboxes if bbox['height'] == bbox['width']]\n",
    "                annotations[k] = {\n",
    "                    'bbox': bboxes,\n",
    "                    'labels': [['Circle'] for bbox in bboxes]\n",
    "                }\n",
    "            i += 1\n",
    "\n",
    "        with open(self.project_path / 'create_results/annotations.json', 'w+') as f:\n",
    "            json.dump(annotations, f)\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _mutate_id(self, bbox: dict, index: int) -> str:\n",
    "        id = '2'\n",
    "        if bbox['height'] == bbox['width']:\n",
    "            id = '1'\n",
    "        return id if index > 8 else str(bbox['id'])\n",
    "\n",
    "    def _bbox_to_label(self, bbox: dict):\n",
    "        if bbox['height'] == bbox['width']:\n",
    "            return ['Circle']\n",
    "        return ['Rectangle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
